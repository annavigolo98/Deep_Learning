{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxom_sKnBh4I",
        "outputId": "2e9bd5dd-2409-4abc-dcb9-8147b80f4b28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls /content/drive/MyDrive/Colab_Notebooks/dataset_nndl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh5ZOTDkQAqS",
        "outputId": "67bd82f2-2254-4fb0-ccf3-8586b2e2970b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "camelyonpatch_level_2_split_test_y.h5.gz.gzip\tcamelyonpatch_level_2_split_valid_y.h5.gz.gzip\n",
            "camelyonpatch_level_2_split_train_y.h5.gz.gzip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!pwd\n",
        "#! cp /content/drive/MyDrive/Colab_Notebooks/dataset_nndl/camelyon* ./\n"
      ],
      "metadata": {
        "id": "-RI1rW3uLIUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4433fb9a-6553-4f2f-957d-3c0509db16b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "camelyonpatch_level_2_split_test_y.h5\tcamelyonpatch_level_2_split_valid_y.h5\tsample_data\n",
            "camelyonpatch_level_2_split_train_y.h5\tdrive\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mv camelyonpatch_level_2_split_test_y.h5.gz.gzip  camelyonpatch_level_2_split_test_y.h5.gz\n",
        "! mv camelyonpatch_level_2_split_valid_y.h5.gz.gzip  camelyonpatch_level_2_split_valid_y.h5.gz\n",
        "! mv camelyonpatch_level_2_split_train_y.h5.gz.gzip  camelyonpatch_level_2_split_train_y.h5.gz\n",
        "! gzip -df camelyonpatch_level_2_split_test_x.h5.gz\n",
        "! gzip -df camelyonpatch_level_2_split_test_y.h5.gz\n",
        "! gzip -df camelyonpatch_level_2_split_valid_x.h5.gz\n",
        "! gzip -df camelyonpatch_level_2_split_valid_y.h5.gz\n",
        "! gzip -df camelyonpatch_level_2_split_train_x.h5.gz\n",
        "! gzip -df camelyonpatch_level_2_split_train_y.h5.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6t9hYJdpR2SD",
        "outputId": "9548338b-28d6-4f93-87c8-f5d6de197534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gzip: camelyonpatch_level_2_split_test_x.h5.gz: No such file or directory\n",
            "gzip: camelyonpatch_level_2_split_valid_x.h5.gz: No such file or directory\n",
            "gzip: camelyonpatch_level_2_split_train_x.h5.gz: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import Compose, ToTensor, RandomAffine, RandomHorizontalFlip, RandomVerticalFlip, ColorJitter\n",
        "import torch\n",
        "import os\n",
        "import pandas as pd\n",
        "import h5py\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "xx5828IELLzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms = Compose([\n",
        "    ToTensor(), #this converts numpy or Pil image to torch tensor and normalizes it in 0, 1\n",
        "    RandomAffine((0.05, 0.05)),\n",
        "    RandomHorizontalFlip(),\n",
        "    RandomVerticalFlip()\n",
        "])"
      ],
      "metadata": {
        "id": "wv0Wxs5_LR3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "dJ9T7NCqLWDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageDataset(Dataset):\n",
        "  def __init__(self, dataset_folder, dataset_type, transform=None):\n",
        "    self.x = h5py.File(os.path.join(dataset_folder, f'camelyonpatch_level_2_split_{dataset_type}_x.h5'), 'r')['x']\n",
        "    self.y = h5py.File(os.path.join(dataset_folder, f'camelyonpatch_level_2_split_{dataset_type}_y.h5'), 'r')['y']\n",
        "    self.transform = transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return min(3200, len(self.x))\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    x = self.x[idx]\n",
        "    y = slef.y[idx]\n",
        "    if self.transform:\n",
        "      x = self.transform(x)\n",
        "    return x,y"
      ],
      "metadata": {
        "id": "pUkdA23GUq6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = ImageDataset('./','train', transforms)\n",
        "valid_dataset = ImageDataset('./', 'valid', ToTensor())\n",
        "test_dataset = ImageDataset('./', 'test', ToTensor())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "ft55t926V_yG",
        "outputId": "d1cd1e90-1471-428d-9646-0158325b49cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = './camelyonpatch_level_2_split_train_x.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-aa7373b137a5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalid_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-44419b2adb27>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset_folder, dataset_type, transform)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mImageDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'camelyonpatch_level_2_split_{dataset_type}_x.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'camelyonpatch_level_2_split_{dataset_type}_y.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 561\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = './camelyonpatch_level_2_split_train_x.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(4, 4, figsize=(6,6))\n",
        "for i in range(16):\n",
        "    axs[i//4][i%4].imshow(train_dataset[i][0].permute(1, 2, 0).numpy())\n",
        "    axs[i//4][i%4].set_xticks([])\n",
        "    axs[i//4][i%4].set_yticks([])\n",
        "    axs[i//4][i%4].set_title(f\"class: {train_dataset[i][1]}\")\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "-bUi4vYFYW2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=64\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=os.cpu_count())\n",
        "valid_dataset = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=os.cpu_count())\n",
        "test_dataset = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=os.cpu.count())\n"
      ],
      "metadata": {
        "id": "-rh9vD-MYb7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Module, Sequential, Conv2d, BatchNorm2d, ReLU\n"
      ],
      "metadata": {
        "id": "eoJWlLPgYzn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MainPath(Module):\n",
        "  def __init__(self, in_channels, filters, kernel_size, stride=1):\n",
        "    super().__init__()\n",
        "    F1, F2, F3 = filters\n",
        "    self.main_path = Sequential(\n",
        "        Conv2d(in_channels, F1, kernel_size=1, stride=stride),\n",
        "        BatchNorm2d(F1),\n",
        "        ReLU(),\n",
        "        Conv2d(F1, F2, kernel_size=kernel_size, padding=kernel_size//2),\n",
        "        BatchNorm2d(F2),\n",
        "        ReLU(),\n",
        "        Conv2d(F2, F3, kernel_size=1),\n",
        "        BatchNorm3d(F3)\n",
        "        )\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "      if isinstance(module, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(module.weight)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()\n",
        "      if isinstance(module, torch.nn.Conv2d):\n",
        "        torch.nn.init_xavier_uniform_(module.weight)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "      y = self.main_path(x)\n",
        "      return y\n",
        "\n",
        "\n",
        "class IdentityBlock(MainPath):\n",
        "  def __init__(self, in_channels, filters, kernel_size):\n",
        "    super().__init__(in_channels, filters, kernel_size)\n",
        "    self.relu = ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = self.relu(self.main_path(x)+x)\n",
        "    return y\n"
      ],
      "metadata": {
        "id": "W_ko34YE2AJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_block = IdentityBlock(3, [100, 100, 3], 3)\n",
        "print(id_block(torch.zeros(1, 3, 10, 10)))\n",
        "print('Expected block')"
      ],
      "metadata": {
        "id": "M5_-4-sO8u_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionalBlock(MainPath):\n",
        "  def __init__(self, in_channels, filters, kernel_size):\n",
        "    super().__init__(in_channels, filters, kernel_size, stride=2)\n",
        "    self.relu = ReLU()\n",
        "    self.shortcut_path = Sequential(Conv2d(in_channels, filters[2], kernel_size=1, stride=2),\n",
        "                                    BatchNorm2d(filters[2]))\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "      if isinstance(module, torch.nn.Linear):\n",
        "        torch.nn.init_xavier_uniform_(module.weight)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()\n",
        "      if isinstance(module, torch.nn.Conv2d):\n",
        "        torch.nn.init_xavier_uniform_(module.weight)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()\n",
        "    def forward(self, x):\n",
        "      y = self.relu(self.main_path(x) + self.shortcut_path(x))\n",
        "      return y\n"
      ],
      "metadata": {
        "id": "Y5Lq1MLvFxSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_block = ConvolutionalBlock(3, [100, 100, 3], 3)\n",
        "print(id_block(torch.zeros(1, 3, 10, 10)).shape)\n",
        "print(\"expected shape: (1, 3, 5, 5)\")"
      ],
      "metadata": {
        "id": "MOUXLwj4_FhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import MaxPool2d, AvgPool2d, Linear, Dropout\n"
      ],
      "metadata": {
        "id": "fH1caYrL_GU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet50(Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.network = Sequential(\n",
        "        Conv2d(3, 64, kernel_size=7, stride=2),\n",
        "        BatchNorm2d(64),\n",
        "        MaxPool2d(kernel_size=3, stride=2),\n",
        "        ConvolutionalBlock(64, [64, 64, 256], kernel_size=3),\n",
        "        Dropout(0.2),\n",
        "        IdentityBlock(256, [64, 64, 256], kernel_size=3),\n",
        "        IdentityBlock(256, [64, 64, 256], kernel_size=3),\n",
        "        ConvolutionalBlock(256, [128, 128, 512], kernel_size=3),\n",
        "        Dropout(0.2),\n",
        "        IdentityBlock(512, [128, 128, 512], kernel_size=3),\n",
        "        IdentityBlock(512, [128, 128, 512], kernel_size=3),\n",
        "        IdentityBlock(512, [128,128, 512], kernel_size=3),\n",
        "        ConvolutionalBlock(512, [256, 256, 1024], kernel_size=3),\n",
        "        Dropout(0.2),\n",
        "        IdentityBlock(1024, [256, 256, 1024], kernel_size=3),\n",
        "        IdentityBlock(1024, [256, 256, 1024], kernel_size=3),\n",
        "        IdentityBlock(1024, [256, 256, 1024], kernel_size=3),\n",
        "        IdentityBlock(1024, [256, 256, 1024], kernel_size=3),\n",
        "        IdentityBlock(1024, [256, 256, 1024], kernel_size=3),\n",
        "        ConvolutionalBlock(1024, [512, 512, 2048], kernel_size=3),\n",
        "        Dropout(0.2),\n",
        "        IdentityBlock(2048, [512, 512, 2048], kernel_size=3),\n",
        "        IdentityBlock(2048, [512, 512, 2048], kernel_size=3),\n",
        "        AvgPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "      self.classification_layer = Linear(2048,1)\n",
        "      self.apply(self._init_weights)\n",
        "\n",
        "    def forward(self, x):\n",
        "      y = self.network(x).reshape((x.shape[0], -1))\n",
        "      y = self.classification_layer(y)\n",
        "      return y\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "      if isinstance(module, torch.nn.Linear):\n",
        "        torch.nn.init_xavier_uniform_(module.weight)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()\n",
        "      if isinstace(module, torch.nn.Conv2d):\n",
        "        torch.nn.init_xavier_uniform_(module.weight)\n",
        "        if module.bias is not None:\n",
        "          module.bias.data.zero_()\n",
        "\n"
      ],
      "metadata": {
        "id": "b5VbX5BBDtz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import SGD, Adam\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "j858W0M7Dt3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet50()\n",
        "opt = SGD(model.parameters(), lr=1e-2, weight_decay=0)\n",
        "loss_fn = BCEWithLogitsLoss()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "epochs=10\n",
        "best_val = np.inf\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  print(f'Epoch: {epoch+1}')\n",
        "  iterator = tqdm(train_dataloader)\n",
        "  for batch_x, batch_y in iterator:\n",
        "    batch_x = batch_x.to(device)\n",
        "    batch_y = batch_y.to(device)\n",
        "    y_pred = model(batch_x)\n",
        "    loss = loss_fn(y_pred, batch_y)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    iterator.set_description(f'Train Loss: {loss.detach().cpu().numpy()}')\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions=[]\n",
        "    true=[]\n",
        "    for batch_x, batch_y in tqdm(valid_dataloader):\n",
        "      batch_x = batch_x.to(device)\n",
        "      batch_y = batch_y.to(device)\n",
        "\n",
        "      y_pred = model(batch_x)\n",
        "      predictions.append(y_pred)\n",
        "      true.append(batch_y)\n",
        "    predictions = torch.cat(predictions, axis=0)\n",
        "    true = torch.cat(true, axis=0)\n",
        "    val_loss = loss_fn(predictions, true)\n",
        "    val_acc = (torch.sigmoid(predictions).round() == true).float().mean()\n",
        "    print(f'Val loss {val_loss}, Val acc {val_acc}')\n",
        "\n",
        "  if val_loss < best_val:\n",
        "    print(\"Saved Model\")\n",
        "    torch.save(model.state_dict(), 'model.pt')\n",
        "    best_val = val_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "32TClyqGJ_lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precosion_recall_fscore_support, roc_curve, roc_auc_score\n",
        "\n",
        "def evaluate_network(dataloader, model, data_split):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions=[]\n",
        "    true=[]\n",
        "    for batch_x, batch_y in tqdm(dataloader):\n",
        "      batch_x = batch_x.to(device)\n",
        "      batch_y = batch_y.to(device)\n",
        "      y_pred = model(batch_x)\n",
        "      predictions.append(y_pred)\n",
        "      true.append(batch_y)\n",
        "    predictions = torch.cat(predictions, axis=0)\n",
        "    true = torch.cat(true, axis=0)\n",
        "    loss = loss_fn(predictions, true).detach().cpu().numpy()\n",
        "    predictions = torch.sigmoid(predictions).detach().cpu().numpy()\n",
        "    true = true.detach().cpu().numpy()\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(true, predictions)\n",
        "    auc = roc_auc_score(true, predictions)\n",
        "    predictions = predictions.round()\n",
        "    precision, recall, fscore, _ = precision_recall_fscore_support(true, predictions, average='binary')\n",
        "    accuracy = accuracy_score(true, predictions)\n",
        "\n",
        "    print(f\"{data_split} loss: {loss}, accuracy: {accuracy}, precision: {precision}, recall: {recall}, f1: {fscore}, roc_auc: {auc}\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % auc)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title(f'{data_split} receiver operating characteristic (ROC)')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UyeLPap5LB8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "evaluate_network(train_dataloader, model, \"Training Dataset\")\n",
        "evaluate_network(valid_dataloader, model, \"Validation Dataset\")\n",
        "evaluate_network(test_dataloader, model, \"Test Dataset\")"
      ],
      "metadata": {
        "id": "kJ_pUaNYNkjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inception Network\n"
      ],
      "metadata": {
        "id": "CVXS-_YCN3qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2d Convolution with Batch Normalization\n",
        "class Conv2d_bn(Module):\n",
        "  #kernel_size, padding and stride can be different per each one of the two dimensions to convolute. So each feature is weighted differently.\n",
        "  def __init__(self, in_filters, out_filters, kernel_size, strides, padding):\n",
        "    super().__init__():\n",
        "    if isinstance(kernel_size, tuple):\n",
        "      padding_val = (kernel_size//2 for k in kernel_size) if padding == 'same' else (0,0)\n",
        "    else:\n",
        "      padding_val = kernel_size//2 if padding == 'same' else 0\n",
        "      self.conv = Conv2d(in_filters, out_filters, kernel_size, strides, padding_val)\n",
        "      self.bn = BatchNorm2d(out_filters)\n",
        "      self.relu = ReLU()\n",
        "      self.apply(self._init_weights)\n",
        "  def _init_weights(self, module):\n",
        "    if isinstance(module, torch.nn.Linear):\n",
        "      torch.nn.init_xavier_uniform_(module.weight)\n",
        "      if module.bias is not None:\n",
        "        module.bias.data.zero_()\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "      torch.nn.init_xavier_uniform_(module.weight)\n",
        "      if module.bias is not None:\n",
        "        module.bias.data.zero_()\n",
        "  def _forward(self, x):\n",
        "    return self.relu(self.bn(self.conv(x)))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9zwbdOFkPiWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Stem Block\n",
        "class StemBlock(Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.first_block = sequential(\n",
        "        Conv2d_bn(in_filters=3, out_filters=32, kernel_size=3, strides=2, padding='valid'),\n",
        "        Conv2d_bn(in_filters=32, out_filters=32, kernel_size=3, strides=1, padding='valid'),\n",
        "        Conv2d_bn(in_filters=32, out_filters=64, kernel_size=3, strides=1, padding='same'),\n",
        "        )\n",
        "    self.first_left = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "    self.first_right = Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, stride=2, padding='valid')\n",
        "\n",
        "    self.second_left = Sequential(\n",
        "        Conv2d_bn(in_filters=160, out_filters=64, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding='valid'),\n",
        "    )\n",
        "    self.second_right = Sequential(\n",
        "        Conv2d_bn(in_filters=160, out_filters=64, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=64, out_filters=64, kernel_size=(7,1), strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=64, out_filters=64, kernel_size=(1,7), strides=1, padding= 'same'),\n",
        "        Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding='valid'),\n",
        "    )\n",
        "\n",
        "    self.third_left = Conv2d_bn(in_filters=192, out_filters=192, kernel_size=3, strides=2, padding='valid')\n",
        "    self.third_right = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.first_block(x)\n",
        "    x_l = self.first_left(x)\n",
        "    x_r = self.first_right(x)\n",
        "    x = torch.cat([x_l, x_r], axis=1)\n",
        "    x_l = self.second_left(x)\n",
        "    x_r = self.second_right(x)\n",
        "    x = torch.cat([x_l, x_r], axis=1)\n",
        "    x_l = self.third_left(x)\n",
        "    x_r = self.third_right(x)\n",
        "    x = torch.cat([x_l, x_r], axis=1)\n",
        "\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "kLKzGNBv1G24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = StemBlock()\n",
        "print(model(torch.zeros((1,3,299,299))).shape)\n",
        "print(f\"Expected shape (1, 384, 35, 35)\")"
      ],
      "metadata": {
        "id": "b_7Ein8C9Rzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inception A block\n",
        "class A_block(Module):\n",
        "  def __init__(self, in_filters):\n",
        "    super().__init__()\n",
        "    self.avg_block = Sequential(\n",
        "        AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=96, kernel_size=1, strides=1, padding='same'),\n",
        "    )\n",
        "\n",
        "    self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=96, kernel_size=1, strides=1, padding='same'),\n",
        "\n",
        "    self.three_by_three_block = Sequential(\n",
        "        Conv2d_bn(in_filters= in_filters, out_filters=64, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding='same'),\n",
        "    )\n",
        "\n",
        "    self.five_by_five_block = Sequential(\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=64, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=64, out_filters=96, kernel_size=3, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=96, out_filters=96, kernel_size=3, strides=1, padding='same'),\n",
        "    )\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_1 = self.avg_block(x)\n",
        "    x_2 = self.one_by_one_block(x)\n",
        "    x_3 = self.three_by_three_block(x)\n",
        "    x_4 = self.five_by_five_block(x)\n",
        "    x = torch.cat([x_1, x_2, x_3, x_4], axis=1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "UnfHfJofGStI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a_block = A_block(384)\n",
        "print(a_block(torch.zeros((1, 384, 35, 35))).shape)\n",
        "print(f\"Expected shape (1, 384, 35, 35)\")"
      ],
      "metadata": {
        "id": "iyXPUdXOGSzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inception_B block\n",
        "class B_block(Module):\n",
        "  def __init__(self, in_filters):\n",
        "    super().__init__()\n",
        "    self.avg_block = Sequential(\n",
        "        AvgPool2d(kernel_size=3, stride=1, padding=1),\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=128, kernel_size=1, strides=1, padding='same'),\n",
        "    )\n",
        "\n",
        "    self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding= 'same')\n",
        "\n",
        "    self.seven_by_seven_block = Sequential(\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=192, out_filters=224, kernel_size=(1,7), strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=224, out_filters=256, kernel_size=(7,1), strides=1, padding='same'),\n",
        "    )\n",
        "\n",
        "    self.thirteen_by_thirteen_block = Sequential(\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=192, out_filters=192, kernel_size=(1,7), strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=192, out_filters=224, kernel_size=(7,1), strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=224, out_filters=224, kernel_size=(1,7), strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=224, out_filters=256, kernel_size=(7,1), strides=1, padding='same'),\n",
        "    )\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.avg_block(x)\n",
        "    x2 = self.one_by_one_block(x)\n",
        "    x3 = self.seven_by_seven_block(x)\n",
        "    x4 = self.thirteen_by_thirteen_block(x)\n",
        "    x = torch.cat([x1, x2, x3, x4], axis = 1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "dbmeMPne_fnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_block = B_block(1024)\n",
        "print(b_block(torch.zeros((1, 1024, 17, 17))).shape)\n",
        "print(f\"Expected shape (1, 1024, 17, 17)\")"
      ],
      "metadata": {
        "id": "JVb8L9T3CKjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inception C block\n",
        "class C_block(Module):\n",
        "  def __init__(self, in_filters):\n",
        "    super().__init__()\n",
        "    self.avg_block = Sequential(\n",
        "        Avg_Pool2d(kernel_size=3, stride=1, padding=1),\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding='same'),\n",
        "    )\n",
        "\n",
        "    self.one_by_one_block = Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding='same')\n",
        "\n",
        "    self.branch_a = Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding='same')\n",
        "\n",
        "    self.branch_a_left = Conv2d_bn(in_filters=384, out_filters=256, kernel_size=(1,3), strides=1, padding='same')\n",
        "\n",
        "    self.branch_a_right = Conv2d_bn(in_filters=384, out_filters=256, kernel_size=(3,1), strides=1, padding='same')\n",
        "\n",
        "    self.branch_b = Sequential(\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=384, out_filters=448, kernel_size=(1,3), strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=448, out_filters=512, kernel_size=(3,1), strides=1, padding='same'),\n",
        "    )\n",
        "\n",
        "    self.branch_b_left = Conv2d_bn(in_filters=512, out_filters=256, kernel_size=(1,3), strides=1, padding='same')\n",
        "\n",
        "    self.branch_b_right = Conv2d_bn(in_filters=512, out_filters=256, kernel_size=(3,1), strides=1, padding='same')\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_1 = self.avg_block(x)\n",
        "    x_2 = self.one_by_one_block(x)\n",
        "    x_a = self.branch_a(x)\n",
        "    x_3 = self.branch_a_left(x_a)\n",
        "    x_4 = self.branch_a_right(x_a)\n",
        "    x_b = self.branch_b(x)\n",
        "    x_5 = self.branch_b_left(x_b)\n",
        "    x_6 = self.branch_b_right(x_b)\n",
        "    x = torch.cat([x_1, x_2, x_3, x_4, x_5, x_6], axis=1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "L5vsfAdoDZeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c_block = C_block(1536)\n",
        "print(c_block(torch.zeros(1, 1536, 8, 8)).shape)\n",
        "print(f\"Expected shape (1, 1536, 8, 8)\")"
      ],
      "metadata": {
        "id": "yo-RD-_6F7Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reduction A block\n",
        "class Reduction_A(Module):\n",
        "  def __init__self(self, in_filters):\n",
        "    super().__init__()\n",
        "    self.max_pool = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "    self.central_block = Conv2d_bn(in_filters=in_filters, out_filters=384, kernel_size=3, strides=2, padding='valid')\n",
        "\n",
        "    self.right_block = Sequential(\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, stride=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=192, out_filters=224, kernel_size=3, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=224, out_filters=256, kernel_size=3, strides=2, padding='valid'),\n",
        "    )\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_1 = self.max_pool(x)\n",
        "    x_2 = self.central_block(x)\n",
        "    x_3 = self.right_block(x)\n",
        "\n",
        "    x = torch.cat([x_1, x_2, x_3], axis=1)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "mOwY3d-mGLK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduction_A = Reduction_A(384)\n",
        "print(reduction_A(torch.zeros(1, 384, 35, 35)).shape)\n",
        "print(\"Expected shape (1, 1024, 17, 17)\")"
      ],
      "metadata": {
        "id": "T0cvaCjjMuiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reduction b block\n",
        "class Reduction_B(Module):\n",
        "  def __init__(self, in_filters):\n",
        "    super().__init__()\n",
        "    self.max_pool = MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "    self.central_block = Sequential(\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=192, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=192, out_filters=192, kernel_size=3, strides=2, padding='valid'),\n",
        "    )\n",
        "\n",
        "    self.right_block = Sequential(\n",
        "        Conv2d_bn(in_filters=in_filters, out_filters=256, kernel_size=1, strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=256, out_filters=256, kernel_size=(1,7), strudes=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=256, out_filters=320, kernel_size=(7,1), strides=1, padding='same'),\n",
        "        Conv2d_bn(in_filters=320, out_filters=320, kernel_size=3, strides=2, padding='valid'),\n",
        "    )\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "        if isinstance(module, torch.nn.Conv2d):\n",
        "            torch.nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                module.bias.data.zero_()\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "        x_1 = self.max_pool(x)\n",
        "        x_2 = self.central_block(x)\n",
        "        x_3 = self.right_block(x)\n",
        "        x = torch.cat([x_1, x_2, x_3], axis=1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "dMO0rwa6M62s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import Dropout"
      ],
      "metadata": {
        "id": "RPRx0q08OWAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionV4(Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.stem = StemBlock()\n",
        "    self.inception_a = Sequential(\n",
        "        A_block(384),\n",
        "        A_block(384),\n",
        "        A_block(384),\n",
        "        A_block(384)\n",
        "    )\n",
        "\n",
        "    self.reduction_a = Reduction_A(384)\n",
        "\n",
        "    self.inception_b = Sequential(\n",
        "        B_block(1024),\n",
        "        B_block(1024),\n",
        "        B_block(1024),\n",
        "        B_block(1024),\n",
        "        B_block(1024),\n",
        "        B_block(1024),\n",
        "        B_block(1024)\n",
        "    )\n",
        "\n",
        "    self.reduction_b = reduction_B(1024)\n",
        "\n",
        "    self.inception_c = Sequential(\n",
        "            C_block(1536),\n",
        "            C_block(1536),\n",
        "            C_block(1536)\n",
        "        )\n",
        "\n",
        "    self.drop = Dropout(0.2)\n",
        "\n",
        "    self.out = Linear(1536, 1)\n",
        "\n",
        "    self.apply(self._init_weights)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.stem(x)\n",
        "    x = self.inception_a(x)\n",
        "    x = self.reduction_a(x)\n",
        "    x = self.inception_b(x)\n",
        "    x = self.reduction_b(x)\n",
        "    x = self.inception_c(x)\n",
        "    x = x.reshape(x.shape[0], -1, 1536).mean(axis=1)\n",
        "    x = self.drop(x)\n",
        "    x = self.out(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "  def _init_weights(self, module):\n",
        "    if isinstance(module, torch.nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(module.weight)\n",
        "        if module.bias is not None:\n",
        "            module.bias.data.zero_()\n",
        "    if isinstance(module, torch.nn.Conv2d):\n",
        "        torch.nn.init.xavier_uniform_(module.weight)\n",
        "        if module.bias is not None:\n",
        "            module.bias.data.zero_()\n"
      ],
      "metadata": {
        "id": "OYRp_9mXOlmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception_v4 = InceptionV4()\n",
        "print(inception_v4(torch.zeros(1, 3, 299, 299)).shape)\n",
        "print(\"Expected shape (1, 1)\")"
      ],
      "metadata": {
        "id": "JEJgP6QfQVl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = InceptionV4()\n",
        "opt = SGD(model.parameters(), lr=0.005)\n",
        "loss_fn = BCELogitsLoss()\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "epochs=10\n",
        "\n",
        "best_val=np.inf\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  model.train()\n",
        "  print(f'Epoch N: {epoch +1}')\n",
        "  iterator = tqdm(train_dataloader)\n",
        "  for x_batch, y_batch in iterator:\n",
        "    x_batch = x_batch.to(device)\n",
        "    y_batch = y_batch.to(device)\n",
        "    y_pred = model(x_batch)\n",
        "\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    iterator.set_description(f'Train_loss {loss.detach().cpu().numpy()}')\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions=[]\n",
        "    true=[]\n",
        "    for x_batch, y_batch in tqdm(val_dataloader):\n",
        "      x_batch = x_batch.to(device)\n",
        "      y_batch = y_batch.to(device)\n",
        "      y_pred = model(x_batch)\n",
        "      predictions.append(y_pred)\n",
        "      true.append(y_batch)\n",
        "    predictions = torch.cat(predictions, axis=0)\n",
        "    true = torch.cat(true, axis=0)\n",
        "    val_loss = loss_fn(predictions, true)\n",
        "\n",
        "    val_acc = (torch.sigmoid(predictions).round() == true).float().mean()\n",
        "    print(f'loss: {val_loss}, accuracy: {val_acc}')\n",
        "\n",
        "    if val_loss < best_val:\n",
        "      print(\"Saved Model\")\n",
        "      torch.save(model.state_dict(), 'model.pt')\n",
        "      best_val = val_loss\n",
        "\n"
      ],
      "metadata": {
        "id": "Ap398VTaQgt5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"model.pt\"))\n",
        "evaluate_network(train_dataloader, model, \"Training Dataset\")\n",
        "evaluate_network(valid_dataloader, model, \"Validation Dataset\")\n",
        "evaluate_network(test_dataloader, model, \"Test Dataset\")"
      ],
      "metadata": {
        "id": "lnXNcPSJfrn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sm2svBaFfv6n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}